{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06cf6575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "CUDA disponível: False\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
    "# !python -m pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# !python -c \"import torch; print(torch.__version__); print('CUDA disponível:', torch.cuda.is_available())\"\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print('CUDA disponível:', torch.cuda.is_available())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb97bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Total de imagens: 829\n",
      "Total de classes: 30\n",
      "Total de imagens: 829\n",
      "Total de classes: 30\n",
      "Total de imagens carregadas: 1658\n",
      "Shape do batch: torch.Size([663, 3, 32, 32])\n",
      "Shape dos rótulos: torch.Size([663])\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from PIL import Image\n",
    "# import torch\n",
    "from torchvision import transforms\n",
    "from io import BytesIO\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"GPU is\", \"available\" if device else \"NOT AVAILABLE\")\n",
    "\n",
    "# Caminho para o arquivo ZIP\n",
    "zip_path = 'Cops_DB.zip'\n",
    "# zip_path2 = 'not-bird.zip'\n",
    "\n",
    "# Transforms para redimensionar e converter para tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),  # Converte para [C x H x W]\n",
    "])\n",
    "\n",
    "# Lista para armazenar os tensores\n",
    "image_in_tensors = []\n",
    "image_out_tensors = []\n",
    "\n",
    "\n",
    "# Abre o ZIP e processa as imagens diretamente\n",
    "# def loadImages(zip_path,label,max):\n",
    "#     count = 0\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         for file_name in zip_ref.namelist():\n",
    "#             if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                 with zip_ref.open(file_name) as file:\n",
    "#                     image = Image.open(BytesIO(file.read())).convert('RGB')\n",
    "#                     tensor = transform(image)  # Shape: [3, 256, 256]\n",
    "#                     #print(tensor.shape)\n",
    "#                     image_in_tensors.append(tensor)\n",
    "#                     image_out_tensors.append([label])\n",
    "#                 count+=1\n",
    "#                 if count%1000 == 0:\n",
    "#                     print(count)\n",
    "                    \n",
    "#                 if count >= max:\n",
    "#                     return\n",
    "                \n",
    "def loadImages(zip_path):\n",
    "    labels_map = {}  # nome_da_pasta -> índice\n",
    "    current_label = 0\n",
    "    count_total = 0\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                parts = file_name.split('/')\n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                class_name = parts[1]\n",
    "                if class_name not in labels_map:\n",
    "                    labels_map[class_name] = current_label\n",
    "                    current_label += 1\n",
    "\n",
    "                label = labels_map[class_name]\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    image = Image.open(BytesIO(file.read())).convert('RGB')\n",
    "                    tensor = transform(image)\n",
    "                    image_in_tensors.append(tensor)\n",
    "                    image_out_tensors.append(label)\n",
    "                count_total += 1\n",
    "\n",
    "    print(f\"Total de imagens: {count_total}\")\n",
    "    print(f\"Total de classes: {len(labels_map)}\")\n",
    "    return labels_map\n",
    "\n",
    "labels_map = loadImages(zip_path)\n",
    "num_classes = len(labels_map)                \n",
    "\n",
    "# Empilha os tensores em um batch\n",
    "loadImages(zip_path)\n",
    "# loadImages(zip_path2,0,5000)\n",
    "\n",
    "print(f'Total de imagens carregadas: {len(image_in_tensors)}')\n",
    "\n",
    "t_x = torch.stack(image_in_tensors)\n",
    "t_y = torch.tensor(image_out_tensors,dtype=torch.long)\n",
    "\n",
    "shuffler = np.random.permutation(len(t_x))\n",
    "\n",
    "x_shuffled = t_x[shuffler]\n",
    "y_shuffled = t_y[shuffler]\n",
    "\n",
    "tlen = len(x_shuffled)\n",
    "l = int(tlen*0.4) #20%\n",
    "xa = x_shuffled[0:l]\n",
    "ya = y_shuffled[0:l]\n",
    "\n",
    "xb = x_shuffled[l:tlen]\n",
    "yb = y_shuffled[l:tlen]\n",
    "\n",
    "t_xt = xa.to(device)\n",
    "t_yt = ya.to(device)\n",
    "\n",
    "\n",
    "\n",
    "dataset = TensorDataset(t_xt, t_yt)\n",
    "#batch_tensor = torch.stack(image_in_tensors)  # Shape: [N, 3, 256, 256]\n",
    "\n",
    "\n",
    "print(f'Shape do batch: {t_xt.shape}')\n",
    "print(f'Shape dos rótulos: {t_yt.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1c08ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 600, validação: 1058\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_idx, val_idx = [], []\n",
    "for label in range(num_classes):\n",
    "    label_indices = (t_y == label).nonzero(as_tuple=True)[0]\n",
    "    train_samples = label_indices[:20]\n",
    "    val_samples = label_indices[20:]\n",
    "    train_idx.extend(train_samples.tolist())\n",
    "    val_idx.extend(val_samples.tolist())\n",
    "\n",
    "x_train, y_train = t_x[train_idx], t_y[train_idx]\n",
    "x_val, y_val = t_x[val_idx], t_y[val_idx]\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Tamanho do treino: {len(train_ds)}, validação: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n",
    "model = CNNClassifier(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 600, validação: 229\n"
     ]
    }
   ],
   "source": [
    "import torch;\n",
    "import torch.nn as nn\n",
    "\n",
    "class RedeCnnBirdNotBird(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RedeCnnBirdNotBird, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(12, 24, 5, stride=1)\n",
    "        self.poll1 = nn.MaxPool2d(2,2)\n",
    "        self.poll2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(864,256)\n",
    "        self.linear2 = nn.Linear(256,1)\n",
    "        #self.linear3 = nn.Linear(164,164)\n",
    "        #self.linear4 = nn.Linear(512,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.poll1(x)\n",
    "        x = self.poll2(x)\n",
    "        \n",
    "        #print(\"x poll1: \",x.size())\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        #print(\"x flatten: \",x.size())\n",
    "        \n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        \n",
    "        #x = torch.relu(self.linear1(x))\n",
    "        #x = torch.relu(self.linear2(x))\n",
    "        #x = torch.tanh(self.linear3(x))\n",
    "        #x = torch.relu(self.linear4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/10 - Loss: 3.4101\n",
      "Época 2/10 - Loss: 3.3948\n",
      "Época 3/10 - Loss: 3.3051\n",
      "Época 4/10 - Loss: 3.1383\n",
      "Época 5/10 - Loss: 2.9496\n",
      "Época 6/10 - Loss: 2.7653\n",
      "Época 7/10 - Loss: 2.6100\n",
      "Época 8/10 - Loss: 2.4372\n",
      "Época 9/10 - Loss: 2.3303\n",
      "Época 10/10 - Loss: 2.2066\n",
      "\n",
      "Acurácia na validação: 21.83%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def trainOld(cnn,dataset, epochs=10):\n",
    "    opt = torch.optim.Adam(cnn.parameters(),lr=0.0001)#0.00001  #0.0000001\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=64, shuffle=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        totalloss = 0\n",
    "        batch = 0\n",
    "        start_time = time.time()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            \n",
    "            #inputs = x[:, :insize]    \n",
    "            #targets = x[:, insize:] \n",
    "            #x = x.to(device) # GPU\n",
    "            x_hat = cnn(inputs)\n",
    "            #print(inputs.size(),\" \",targets.size(),\" \",x_hat.size())\n",
    "            loss = ((targets - x_hat)**2).sum()\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            totalloss+=loss\n",
    "            batch+=1\n",
    " \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            #print(\"step: \")\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(epoch,\" Total Loss: \",(totalloss/len(dataset)),\" time \",(end_time-start_time))\n",
    "        #if epoch%250==0:\n",
    "        #    torch.save(cnn, \"backup_training_gam_v02.pth\")\n",
    "    return cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae5aed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(cnn,dataset, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataset:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataset)}')\n",
    "\n",
    "    return cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.40944472739571\n",
      "Epoch 2, Loss: 3.3945072889328003\n",
      "Epoch 3, Loss: 3.3145860182611564\n",
      "Epoch 4, Loss: 3.086020093215139\n",
      "Epoch 5, Loss: 2.8526153062519275\n",
      "Epoch 6, Loss: 2.66401375594892\n",
      "Epoch 7, Loss: 2.4789590521862634\n",
      "Epoch 8, Loss: 2.3019910141041406\n",
      "Epoch 9, Loss: 2.2042783185055383\n",
      "Epoch 10, Loss: 2.0337852239608765\n",
      "Epoch 11, Loss: 1.8593720103565015\n",
      "Epoch 12, Loss: 1.6907846896271956\n",
      "Epoch 13, Loss: 1.5767765358874672\n",
      "Epoch 14, Loss: 1.4157531920232271\n",
      "Epoch 15, Loss: 1.2284743644689258\n",
      "Epoch 16, Loss: 1.037464373990109\n",
      "Epoch 17, Loss: 0.8855181838336744\n",
      "Epoch 18, Loss: 0.794564953760097\n",
      "Epoch 19, Loss: 0.6232949303169\n",
      "Epoch 20, Loss: 0.5369615319528078\n",
      "Epoch 21, Loss: 0.4397844766315661\n",
      "Epoch 22, Loss: 0.3686230406165123\n",
      "Epoch 23, Loss: 0.2669883901743512\n",
      "Epoch 24, Loss: 0.25114631143055466\n",
      "Epoch 25, Loss: 0.17766035955987478\n",
      "Epoch 26, Loss: 0.17167082968118944\n",
      "Epoch 27, Loss: 0.13480623223279653\n",
      "Epoch 28, Loss: 0.14273068828410224\n",
      "Epoch 29, Loss: 0.0929309414013436\n",
      "Epoch 30, Loss: 0.06468285372676819\n",
      "Epoch 31, Loss: 0.04062688733009916\n",
      "Epoch 32, Loss: 0.03084790902702432\n",
      "Epoch 33, Loss: 0.023568671515309496\n",
      "Epoch 34, Loss: 0.021043669456910146\n",
      "Epoch 35, Loss: 0.01756639680580089\n",
      "Epoch 36, Loss: 0.015373925310804656\n",
      "Epoch 37, Loss: 0.014419360968627427\n",
      "Epoch 38, Loss: 0.012516936495606052\n",
      "Epoch 39, Loss: 0.010970542121580556\n",
      "Epoch 40, Loss: 0.010127141042367407\n",
      "Epoch 41, Loss: 0.00915421276524859\n",
      "Epoch 42, Loss: 0.008245207087479924\n",
      "Epoch 43, Loss: 0.007678488140778714\n",
      "Epoch 44, Loss: 0.0072481865430937\n",
      "Epoch 45, Loss: 0.006760964053682983\n",
      "Epoch 46, Loss: 0.006107258892275001\n",
      "Epoch 47, Loss: 0.005823367391712964\n",
      "Epoch 48, Loss: 0.005211170284861797\n",
      "Epoch 49, Loss: 0.004907729496297084\n",
      "Epoch 50, Loss: 0.004804224413084357\n",
      "Epoch 51, Loss: 0.004398880330355544\n",
      "Epoch 52, Loss: 0.004175302008853147\n",
      "Epoch 53, Loss: 0.003962529541336392\n",
      "Epoch 54, Loss: 0.0037968597025610507\n",
      "Epoch 55, Loss: 0.0035814455140529104\n",
      "Epoch 56, Loss: 0.0033145468761703292\n",
      "Epoch 57, Loss: 0.0031695587585042965\n",
      "Epoch 58, Loss: 0.003037078912664009\n",
      "Epoch 59, Loss: 0.002902564577341668\n",
      "Epoch 60, Loss: 0.0027702429644322316\n",
      "Epoch 61, Loss: 0.002583180955537644\n",
      "Epoch 62, Loss: 0.002485422098911122\n",
      "Epoch 63, Loss: 0.002401819565995155\n",
      "Epoch 64, Loss: 0.0022539333654812686\n",
      "Epoch 65, Loss: 0.0021903952185407674\n",
      "Epoch 66, Loss: 0.0020640299526827506\n",
      "Epoch 67, Loss: 0.0019822201544516965\n",
      "Epoch 68, Loss: 0.0018865226853736921\n",
      "Epoch 69, Loss: 0.0018325488689649653\n",
      "Epoch 70, Loss: 0.0017673624464996944\n",
      "Epoch 71, Loss: 0.001729747819665231\n",
      "Epoch 72, Loss: 0.0016247943490988721\n",
      "Epoch 73, Loss: 0.0015426296694816923\n",
      "Epoch 74, Loss: 0.0014990220263012145\n",
      "Epoch 75, Loss: 0.0014352724048014927\n",
      "Epoch 76, Loss: 0.0013661351465424033\n",
      "Epoch 77, Loss: 0.0013235820101966198\n",
      "Epoch 78, Loss: 0.0012684678199308876\n",
      "Epoch 79, Loss: 0.0012618553699116763\n",
      "Epoch 80, Loss: 0.0012050578140923264\n",
      "Epoch 81, Loss: 0.001137791261977614\n",
      "Epoch 82, Loss: 0.0010967271580164762\n",
      "Epoch 83, Loss: 0.0010631060209370365\n",
      "Epoch 84, Loss: 0.0010231722798811173\n",
      "Epoch 85, Loss: 0.000996402003741088\n",
      "Epoch 86, Loss: 0.0009668971041192938\n",
      "Epoch 87, Loss: 0.0009238904688237725\n",
      "Epoch 88, Loss: 0.0008966386590863726\n",
      "Epoch 89, Loss: 0.0008735374461761431\n",
      "Epoch 90, Loss: 0.0008377938218855936\n",
      "Epoch 91, Loss: 0.0008214154429304855\n",
      "Epoch 92, Loss: 0.0007904800211116182\n",
      "Epoch 93, Loss: 0.0007616000293637626\n",
      "Epoch 94, Loss: 0.0007330979784264377\n",
      "Epoch 95, Loss: 0.000715758028443241\n",
      "Epoch 96, Loss: 0.0006944646087695697\n",
      "Epoch 97, Loss: 0.0006719511431200724\n",
      "Epoch 98, Loss: 0.0006551118506314723\n",
      "Epoch 99, Loss: 0.0006271841312378743\n",
      "Epoch 100, Loss: 0.0006122087437880078\n"
     ]
    }
   ],
   "source": [
    "# cnn = RedeCnnBirdNotBird().to(device)\n",
    "# cnn = trainOld(cnn, dataset,epochs=100)\n",
    "\n",
    "cnn = CNNClassifier(num_classes).to(device)\n",
    "cnn = train(cnn, train_dl, epochs=100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaMetricasOld(dataset,cnn):\n",
    "    tabela_verdade = [\n",
    "        [0, 0],  # classe 0\n",
    "        [0, 0]   # classe 1\n",
    "    ]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        x_hat = cnn(inputs)\n",
    "        classe = 0\n",
    "        if x_hat[0] > 0.5:\n",
    "            classe = 1\n",
    "            \n",
    "        #print(targets[0][0])\n",
    "        tabela_verdade[classe][int(targets[0][0])]+=1\n",
    "        \n",
    "    print(tabela_verdade)\n",
    "\n",
    "    print('   B','   NB')\n",
    "    print('PB ',tabela_verdade[1][1],' ',tabela_verdade[1][0])\n",
    "    print('PNB ',tabela_verdade[0][1],' ',tabela_verdade[0][0])\n",
    "\n",
    "    VP = tabela_verdade[1][1]\n",
    "    FP = tabela_verdade[1][0]\n",
    "    FN = tabela_verdade[0][1]\n",
    "    VN = tabela_verdade[0][0]\n",
    "    Total = VP+FP+FN+VN\n",
    "    ACC = (VP+VN)/Total\n",
    "    PRE = VP/(VP+FP)\n",
    "    REV = VP/(VP+FN)\n",
    "    F1 = (PRE*REV/(PRE+REV))*2\n",
    "\n",
    "    print(\"ACC \",ACC)\n",
    "    print(\"PRE \",PRE)\n",
    "    print(\"REV \",REV)\n",
    "    print(\"F1 \",F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63660bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def calculaMetricas(dataset, model, device='cpu', nomes_classes=None):\n",
    "    model.eval()\n",
    "    num_classes = len(torch.unique(dataset.tensors[1]))  # detecta nº de classes\n",
    "    confusion = torch.zeros(num_classes, num_classes, dtype=torch.int32)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            confusion[predicted.item(), targets.item()] += 1\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    total = confusion.sum().item()\n",
    "    correct = confusion.diag().sum().item()\n",
    "    acc = correct / total if total > 0 else 0\n",
    "\n",
    "    # Ajuste de largura para o nome da classe\n",
    "    largura_nome = max(len(nome) for nome in nomes_classes) + 4 if nomes_classes else 20\n",
    "\n",
    "    print(\"\\n===================== RESULTADOS POR CLASSE =====================\")\n",
    "    print(f\"{'Classe':<{largura_nome}}{'FP':<8}{'FN':<8}{'TP':<8}{'Precisão':<12}{'Revocação':<12}{'F1-score':<10}\")\n",
    "    print(\"-\" * (largura_nome + 55))\n",
    "\n",
    "    precision, recall, f1 = [], [], []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        TP = confusion[c, c].item()\n",
    "        FP = confusion[c, :].sum().item() - TP\n",
    "        FN = confusion[:, c].sum().item() - TP\n",
    "\n",
    "        pre = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        rec = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1c = (2 * pre * rec) / (pre + rec) if (pre + rec) > 0 else 0\n",
    "\n",
    "        precision.append(pre)\n",
    "        recall.append(rec)\n",
    "        f1.append(f1c)\n",
    "\n",
    "        nome_classe = nomes_classes[c] if nomes_classes and c < len(nomes_classes) else f\"Planta{c+1}\"\n",
    "        print(f\"{nome_classe:<{largura_nome}}{FP:<8}{FN:<8}{TP:<8}{pre:<12.4f}{rec:<12.4f}{f1c:<10.4f}\")\n",
    "\n",
    "    print(\"-\" * (largura_nome + 55))\n",
    "    print(f\"Acurácia geral: {acc:.4f}\")\n",
    "    print(f\"Precisão média: {np.mean(precision):.4f}\")\n",
    "    print(f\"Revocação média: {np.mean(recall):.4f}\")\n",
    "    print(f\"F1-score médio: {np.mean(f1):.4f}\")\n",
    "    print(\"=\" * (largura_nome + 55))\n",
    "\n",
    "    return confusion, acc, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ad90a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def obter_nomes_classes_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        nomes_classes = set()\n",
    "        for file_name in zip_ref.namelist():\n",
    "            partes = file_name.split('/')\n",
    "            if len(partes) > 1 and partes[1] != '':\n",
    "                nomes_classes.add(partes[1])\n",
    "        \n",
    "        nomes_classes = sorted(list(nomes_classes))\n",
    "        return nomes_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9dc7588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Treinamento ---------------------------------\n",
      "\n",
      "===================== RESULTADOS POR CLASSE =====================\n",
      "Classe                 FP      FN      TP      Precisão    Revocação   F1-score  \n",
      "------------------------------------------------------------------------------\n",
      "Cherry                 2       6       21      0.9130      0.7778      0.8400    \n",
      "Coffee-plant           6       9       14      0.7000      0.6087      0.6512    \n",
      "Cucumber               3       4       16      0.8421      0.8000      0.8205    \n",
      "Fox_nut(Makhana)       5       0       14      0.7368      1.0000      0.8485    \n",
      "Lemon                  4       6       16      0.8000      0.7273      0.7619    \n",
      "Olive-tree             6       7       16      0.7273      0.6957      0.7111    \n",
      "Pearl_millet(bajra)    4       10      24      0.8571      0.7059      0.7742    \n",
      "Tobacco-plant          2       7       20      0.9091      0.7407      0.8163    \n",
      "almond                 4       0       15      0.7895      1.0000      0.8824    \n",
      "banana                 6       7       20      0.7692      0.7407      0.7547    \n",
      "cardamom               0       1       10      1.0000      0.9091      0.9524    \n",
      "chilli                 0       2       22      1.0000      0.9167      0.9565    \n",
      "clove                  2       6       18      0.9000      0.7500      0.8182    \n",
      "coconut                6       2       24      0.8000      0.9231      0.8571    \n",
      "cotton                 3       13      18      0.8571      0.5806      0.6923    \n",
      "gram                   3       4       11      0.7857      0.7333      0.7586    \n",
      "jowar                  6       4       25      0.8065      0.8621      0.8333    \n",
      "jute                   3       3       15      0.8333      0.8333      0.8333    \n",
      "maize                  7       8       22      0.7586      0.7333      0.7458    \n",
      "mustard-oil            3       2       19      0.8636      0.9048      0.8837    \n",
      "papaya                 6       1       12      0.6667      0.9231      0.7742    \n",
      "pineapple              5       3       19      0.7917      0.8636      0.8261    \n",
      "rice                   0       4       18      1.0000      0.8182      0.9000    \n",
      "soyabean               13      3       19      0.5938      0.8636      0.7037    \n",
      "sugarcane              5       2       22      0.8148      0.9167      0.8627    \n",
      "sunflower              1       2       13      0.9286      0.8667      0.8966    \n",
      "tea                    8       1       20      0.7143      0.9524      0.8163    \n",
      "tomato                 1       3       19      0.9500      0.8636      0.9048    \n",
      "vigna-radiati(Mung)    4       4       15      0.7895      0.7895      0.7895    \n",
      "wheat                  7       1       21      0.7500      0.9545      0.8400    \n",
      "------------------------------------------------------------------------------\n",
      "Acurácia geral: 0.8115\n",
      "Precisão média: 0.8216\n",
      "Revocação média: 0.8252\n",
      "F1-score médio: 0.8169\n",
      "==============================================================================\n",
      "------------------- TESTE ---------------------------------\n",
      "\n",
      "===================== RESULTADOS POR CLASSE =====================\n",
      "Classe                 FP      FN      TP      Precisão    Revocação   F1-score  \n",
      "------------------------------------------------------------------------------\n",
      "Cherry                 6       16      21      0.7778      0.5676      0.6562    \n",
      "Coffee-plant           12      9       26      0.6842      0.7429      0.7123    \n",
      "Cucumber               7       16      26      0.7879      0.6190      0.6933    \n",
      "Fox_nut(Makhana)       9       2       30      0.7692      0.9375      0.8451    \n",
      "Lemon                  12      8       26      0.6842      0.7647      0.7222    \n",
      "Olive-tree             8       11      26      0.7647      0.7027      0.7324    \n",
      "Pearl_millet(bajra)    8       12      32      0.8000      0.7273      0.7619    \n",
      "Tobacco-plant          6       13      26      0.8125      0.6667      0.7324    \n",
      "almond                 12      2       25      0.6757      0.9259      0.7813    \n",
      "banana                 4       15      20      0.8333      0.5714      0.6780    \n",
      "cardamom               0       3       30      1.0000      0.9091      0.9524    \n",
      "chilli                 8       0       22      0.7333      1.0000      0.8462    \n",
      "clove                  4       14      22      0.8462      0.6111      0.7097    \n",
      "coconut                4       4       20      0.8333      0.8333      0.8333    \n",
      "cotton                 9       7       26      0.7429      0.7879      0.7647    \n",
      "gram                   9       4       31      0.7750      0.8857      0.8267    \n",
      "jowar                  8       8       23      0.7419      0.7419      0.7419    \n",
      "jute                   1       3       25      0.9615      0.8929      0.9259    \n",
      "maize                  5       8       24      0.8276      0.7500      0.7869    \n",
      "mustard-oil            3       4       31      0.9118      0.8857      0.8986    \n",
      "papaya                 10      3       30      0.7500      0.9091      0.8219    \n",
      "pineapple              9       7       21      0.7000      0.7500      0.7241    \n",
      "rice                   2       2       34      0.9444      0.9444      0.9444    \n",
      "soyabean               11      5       33      0.7500      0.8684      0.8049    \n",
      "sugarcane              5       0       26      0.8387      1.0000      0.9123    \n",
      "sunflower              7       6       27      0.7941      0.8182      0.8060    \n",
      "tea                    12      3       22      0.6471      0.8800      0.7458    \n",
      "tomato                 3       5       25      0.8929      0.8333      0.8621    \n",
      "vigna-radiati(Mung)    6       10      25      0.8065      0.7143      0.7576    \n",
      "wheat                  1       1       39      0.9750      0.9750      0.9750    \n",
      "------------------------------------------------------------------------------\n",
      "Acurácia geral: 0.7980\n",
      "Precisão média: 0.8021\n",
      "Revocação média: 0.8072\n",
      "F1-score médio: 0.7985\n",
      "==============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[21,  1,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0],\n",
       "         [ 2, 26,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  5,  0,  1,  1,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "         [ 0,  0, 26,  0,  0,  0,  0,  3,  0,  2,  0,  0,  2,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 2,  0,  0, 30,  0,  1,  2,  1,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 3,  0,  1,  0, 26,  1,  0,  2,  0,  2,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0, 26,  0,  0,  0,  0,  0,  0,  0,  1,  3,  0,  2,  0,\n",
       "           0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0, 32,  0,  0,  0,  0,  0,  0,  0,  0,  2,  4,  0,\n",
       "           0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0, 26,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  2,  0,  0,  0,  1,  0,  0,  2,  0],\n",
       "         [ 0,  1,  0,  0,  0,  2,  0,  2, 25,  0,  1,  0,  1,  0,  1,  0,  2,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0],\n",
       "         [ 0,  0,  1,  0,  0,  0,  0,  2,  0, 20,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 30,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0, 22,  0,  2,  0,  0,  0,  0,\n",
       "           0,  2,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0, 22,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  2,  0],\n",
       "         [ 4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 2,  0,  0,  2,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0, 26,  0,  0,  0,\n",
       "           0,  1,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  1,  3,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  1, 31,  0,  0,\n",
       "           2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  2,  0,  0,  0, 23,  0,\n",
       "           2,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 25,\n",
       "           1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  2,  0,  0,  0,  0,  1,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0, 31,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0],\n",
       "         [ 0,  0,  2,  0,  4,  2,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  3,  0,  0,  0,  0,  2,  1,  0,  2,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0, 21,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0, 34,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  1,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "           2,  0,  0,  0,  1, 33,  0,  1,  0,  0,  3,  0],\n",
       "         [ 0,  0,  2,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0, 26,  0,  0,  0,  0,  0],\n",
       "         [ 0,  2,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0, 27,  0,  0,  0,  1],\n",
       "         [ 0,  0,  2,  0,  0,  0,  1,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  3,\n",
       "           1,  0,  0,  0,  0,  0,  0,  0, 22,  0,  3,  0],\n",
       "         [ 2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0, 25,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  5,  0,  0,  0,  0, 25,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 39]], dtype=torch.int32),\n",
       " 0.7979899497487437,\n",
       " [0.7777777777777778,\n",
       "  0.6842105263157895,\n",
       "  0.7878787878787878,\n",
       "  0.7692307692307693,\n",
       "  0.6842105263157895,\n",
       "  0.7647058823529411,\n",
       "  0.8,\n",
       "  0.8125,\n",
       "  0.6756756756756757,\n",
       "  0.8333333333333334,\n",
       "  1.0,\n",
       "  0.7333333333333333,\n",
       "  0.8461538461538461,\n",
       "  0.8333333333333334,\n",
       "  0.7428571428571429,\n",
       "  0.775,\n",
       "  0.7419354838709677,\n",
       "  0.9615384615384616,\n",
       "  0.8275862068965517,\n",
       "  0.9117647058823529,\n",
       "  0.75,\n",
       "  0.7,\n",
       "  0.9444444444444444,\n",
       "  0.75,\n",
       "  0.8387096774193549,\n",
       "  0.7941176470588235,\n",
       "  0.6470588235294118,\n",
       "  0.8928571428571429,\n",
       "  0.8064516129032258,\n",
       "  0.975],\n",
       " [0.5675675675675675,\n",
       "  0.7428571428571429,\n",
       "  0.6190476190476191,\n",
       "  0.9375,\n",
       "  0.7647058823529411,\n",
       "  0.7027027027027027,\n",
       "  0.7272727272727273,\n",
       "  0.6666666666666666,\n",
       "  0.9259259259259259,\n",
       "  0.5714285714285714,\n",
       "  0.9090909090909091,\n",
       "  1.0,\n",
       "  0.6111111111111112,\n",
       "  0.8333333333333334,\n",
       "  0.7878787878787878,\n",
       "  0.8857142857142857,\n",
       "  0.7419354838709677,\n",
       "  0.8928571428571429,\n",
       "  0.75,\n",
       "  0.8857142857142857,\n",
       "  0.9090909090909091,\n",
       "  0.75,\n",
       "  0.9444444444444444,\n",
       "  0.868421052631579,\n",
       "  1.0,\n",
       "  0.8181818181818182,\n",
       "  0.88,\n",
       "  0.8333333333333334,\n",
       "  0.7142857142857143,\n",
       "  0.975],\n",
       " [0.65625,\n",
       "  0.7123287671232877,\n",
       "  0.6933333333333334,\n",
       "  0.8450704225352113,\n",
       "  0.7222222222222222,\n",
       "  0.7323943661971832,\n",
       "  0.761904761904762,\n",
       "  0.7323943661971831,\n",
       "  0.7812500000000001,\n",
       "  0.6779661016949152,\n",
       "  0.9523809523809523,\n",
       "  0.846153846153846,\n",
       "  0.7096774193548387,\n",
       "  0.8333333333333334,\n",
       "  0.7647058823529412,\n",
       "  0.8266666666666667,\n",
       "  0.7419354838709677,\n",
       "  0.9259259259259259,\n",
       "  0.7868852459016394,\n",
       "  0.8985507246376812,\n",
       "  0.821917808219178,\n",
       "  0.7241379310344827,\n",
       "  0.9444444444444444,\n",
       "  0.8048780487804879,\n",
       "  0.9122807017543859,\n",
       "  0.8059701492537314,\n",
       "  0.7457627118644068,\n",
       "  0.8620689655172413,\n",
       "  0.7575757575757576,\n",
       "  0.975])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_plantas = obter_nomes_classes_zip('Cops_DB.zip')\n",
    "\n",
    "print(\"------------------- Treinamento ---------------------------------\")\n",
    "calculaMetricas(dataset,cnn, device, nome_plantas)\n",
    "print(\"------------------- TESTE ---------------------------------\")\n",
    "t_xtb = xb.to(device)\n",
    "t_ytb = yb.to(device)\n",
    "datasetb = TensorDataset(t_xtb, t_ytb)\n",
    "calculaMetricas(datasetb,cnn, device, nome_plantas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4020e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Total de imagens: 829\n",
      "Total de classes: 30\n",
      "Tamanho do treino: 600, validação: 229\n",
      "Época 1/10 - Loss: 3.4152\n",
      "Época 2/10 - Loss: 3.3018\n",
      "Época 3/10 - Loss: 2.9650\n",
      "Época 4/10 - Loss: 2.5928\n",
      "Época 5/10 - Loss: 2.2759\n",
      "Época 6/10 - Loss: 1.9404\n",
      "Época 7/10 - Loss: 1.6452\n",
      "Época 8/10 - Loss: 1.3162\n",
      "Época 9/10 - Loss: 0.9873\n",
      "Época 10/10 - Loss: 0.7131\n",
      "\n",
      "Acurácia na validação: 33.19%\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURAÇÕES\n",
    "# ============================================================\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Usando dispositivo:\", device)\n",
    "\n",
    "zip_path = 'Cops_DB.zip'  # Caminho do dataset compactado\n",
    "IMG_SIZE = (64, 64)       # Tamanho padronizado\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# ============================================================\n",
    "# TRANSFORMAÇÃO DAS IMAGENS\n",
    "# ============================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# LISTAS PARA ARMAZENAR TENSORES\n",
    "# ============================================================\n",
    "image_in_tensors = []\n",
    "image_out_tensors = []\n",
    "\n",
    "# ============================================================\n",
    "# FUNÇÃO PARA LER AS IMAGENS DO ZIP\n",
    "# ============================================================\n",
    "def loadImages(zip_path):\n",
    "    labels_map = {}  # nome_da_pasta -> índice\n",
    "    current_label = 0\n",
    "    count_total = 0\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                parts = file_name.split('/')\n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                class_name = parts[1]\n",
    "                if class_name not in labels_map:\n",
    "                    labels_map[class_name] = current_label\n",
    "                    current_label += 1\n",
    "\n",
    "                label = labels_map[class_name]\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    image = Image.open(BytesIO(file.read())).convert('RGB')\n",
    "                    tensor = transform(image)\n",
    "                    image_in_tensors.append(tensor)\n",
    "                    image_out_tensors.append(label)\n",
    "                count_total += 1\n",
    "\n",
    "    print(f\"Total de imagens: {count_total}\")\n",
    "    print(f\"Total de classes: {len(labels_map)}\")\n",
    "    return labels_map\n",
    "\n",
    "labels_map = loadImages(zip_path)\n",
    "num_classes = len(labels_map)\n",
    "\n",
    "# ============================================================\n",
    "# CONVERTE LISTAS PARA TENSORES E EMBARALHA\n",
    "# ============================================================\n",
    "t_x = torch.stack(image_in_tensors)\n",
    "t_y = torch.tensor(image_out_tensors, dtype=torch.long)\n",
    "\n",
    "indices = np.random.permutation(len(t_x))\n",
    "t_x = t_x[indices]\n",
    "t_y = t_y[indices]\n",
    "\n",
    "# ============================================================\n",
    "# SEPARA TREINO (20 imagens por classe) e VALIDAÇÃO\n",
    "# ============================================================\n",
    "train_idx, val_idx = [], []\n",
    "for label in range(num_classes):\n",
    "    label_indices = (t_y == label).nonzero(as_tuple=True)[0]\n",
    "    train_samples = label_indices[:20]\n",
    "    val_samples = label_indices[20:]\n",
    "    train_idx.extend(train_samples.tolist())\n",
    "    val_idx.extend(val_samples.tolist())\n",
    "\n",
    "x_train, y_train = t_x[train_idx], t_y[train_idx]\n",
    "x_val, y_val = t_x[val_idx], t_y[val_idx]\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Tamanho do treino: {len(train_ds)}, validação: {len(val_ds)}\")\n",
    "\n",
    "# ============================================================\n",
    "# REDE NEURAL CONVOLUCIONAL SIMPLES\n",
    "# ============================================================\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * (IMG_SIZE[0]//4) * (IMG_SIZE[1]//4), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "model = CNNClassifier(num_classes).to(device)\n",
    "\n",
    "# ============================================================\n",
    "# TREINAMENTO\n",
    "# ============================================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Época {epoch+1}/{EPOCHS} - Loss: {total_loss/len(train_dl):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# AVALIAÇÃO (VALIDAÇÃO)\n",
    "# ============================================================\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb)\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        total += yb.size(0)\n",
    "        correct += (predicted == yb).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"\\nAcurácia na validação: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
